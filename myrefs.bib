
@misc{noauthor_scientists_2017,
	title = {Scientists apply generative neural network to create new pharmaceutical medicines},
	url = {http://www.news-medical.net/news/20170209/Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.aspx},
	abstract = {Scientists from Mail.Ru Group, Insilico Medicine and MIPT have for the first time applied a generative neural network to create new pharmaceutical medicines with the desired characteristics.},
	urldate = {2017-02-23},
	journal = {News-Medical.net},
	month = feb,
	year = {2017},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\J5FX8R77\\Scientists-apply-generative-neural-network-to-create-new-pharmaceutical-medicines.html:text/html}
}

@article{kadurin_cornucopia_2016,
	title = {The cornucopia of meaningful leads: {Applying} deep adversarial autoencoders for new molecule development in oncology},
	volume = {8},
	issn = {1949-2553},
	shorttitle = {The cornucopia of meaningful leads},
	url = {http://www.impactjournals.com/oncotarget/index.php?journal=oncotarget&page=article&op=view&path%5B0%5D=14073&path%5B1%5D=44886},
	doi = {10.18632/oncotarget.14073},
	abstract = {Oncotarget {\textbar} doi:10.18632/oncotarget.14073. Artur Kadurin, Alexander Aliper, Andrey Kazennov, Polina Mamoshina, Quentin Vanhaelen, Kuzma Khrabrov, Alex Zhavoronkov},
	number = {7},
	urldate = {2017-02-23},
	journal = {Oncotarget},
	author = {Kadurin, Artur and Aliper, Alexander and Kazennov, Andrey and Mamoshina, Polina and Vanhaelen, Quentin and Khrabrov, Kuzma and Zhavoronkov, Alex and Kadurin, Artur and Aliper, Alexander and Kazennov, Andrey and Mamoshina, Polina and Vanhaelen, Quentin and Khrabrov, Kuzma and Zhavoronkov, Alex},
	month = dec,
	year = {2016},
	pages = {10883--10890},
	file = {Kadurin et al_2016_The cornucopia of meaningful leads.pdf:C\:\\Users\\Benjamin Hillmann\\OneDrive\\Documents\\Zotfile\\Kadurin et al_2016_The cornucopia of meaningful leads.pdf:application/pdf;Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\VS5R8K3J\\index.html:text/html}
}

@article{noauthor_ct_nodate,
	title = {{CT} {Scan} {Based} {Brain} {Tumor} {Detection} using {Radon} {Transform} and {Neural} {Networks} ({PDF} {Download} {Available})},
	url = {https://www.researchgate.net/publication/291102843_CT_Scan_Based_Brain_Tumor_Detection_using_Radon_Transform_and_Neural_Networks},
	abstract = {Official Full-Text Publication: CT Scan Based Brain Tumor Detection using Radon Transform and Neural Networks on ResearchGate, the professional network for scientists.},
	urldate = {2017-02-23},
	journal = {ResearchGate},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\TS7UE97K\\291102843_CT_Scan_Based_Brain_Tumor_Detection_using_Radon_Transform_and_Neural_Networks.html:text/html}
}

@misc{noauthor_google_nodate,
	title = {Google is using its deep learning tech to diagnose disease},
	url = {http://www.popsci.com/google-applied-technology-they-use-to-sort-photos-to-diagnose-diabetic-eye-problems},
	abstract = {And it performs (slightly) better than human doctors do},
	urldate = {2017-02-23},
	journal = {Popular Science},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\N2DCJFVS\\google-applied-technology-they-use-to-sort-photos-to-diagnose-diabetic-eye-problems.html:text/html}
}

@article{van_tulder_combining_2016,
	title = {Combining {Generative} and {Discriminative} {Representation} {Learning} for {Lung} {CT} {Analysis} {With} {Convolutional} {Restricted} {Boltzmann} {Machines}},
	volume = {35},
	issn = {0278-0062, 1558-254X},
	url = {http://ieeexplore.ieee.org/document/7401039/},
	doi = {10.1109/TMI.2016.2526687},
	number = {5},
	urldate = {2017-02-23},
	journal = {IEEE Transactions on Medical Imaging},
	author = {van Tulder, Gijs and de Bruijne, Marleen},
	month = may,
	year = {2016},
	pages = {1262--1272},
	file = {vantulder-2016-tmi-final.pdf:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\IR2RUTIG\\vantulder-2016-tmi-final.pdf:application/pdf}
}

@article{litjens_survey_2017,
	title = {A {Survey} on {Deep} {Learning} in {Medical} {Image} {Analysis}},
	volume = {1702},
	url = {http://adsabs.harvard.edu/abs/2017arXiv170205747L},
	abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks and provide concise overviews of studies per application area. Open challenges and directions for future research are discussed.},
	urldate = {2017-02-27},
	journal = {ArXiv e-prints},
	author = {Litjens, Geert and Kooi, Thijs and Ehteshami Bejnordi, Babak and Arindra Adiyoso Setio, Arnaud and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A. W. M. and van Ginneken, Bram and Sánchez, Clara I.},
	month = feb,
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {arXiv:1702.05747},
	file = {1702.pdf:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\E2GE349B\\1702.pdf:application/pdf}
}

@inproceedings{ronneberger_u-net:_2015,
	title = {U-net: {Convolutional} networks for biomedical image segmentation},
	shorttitle = {U-net},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-24574-4_28},
	urldate = {2017-03-10},
	booktitle = {International {Conference} on {Medical} {Image} {Computing} and {Computer}-{Assisted} {Intervention}},
	publisher = {Springer},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year = {2015},
	pages = {234--241},
	file = {1505.04597v1.pdf:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\4JZC8KU5\\1505.04597v1.pdf:application/pdf}
}

@misc{noauthor_luna16_nodate,
	title = {{LUNA}16 - {Data}},
	url = {https://luna16.grand-challenge.org/data/},
	urldate = {2017-03-10},
	file = {LUNA16 - Data:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\NXESWXUK\\data.html:text/html}
}

@article{armato_lung_2011,
	title = {The {Lung} {Image} {Database} {Consortium} ({LIDC}) and {Image} {Database} {Resource} {Initiative} ({IDRI}): a completed reference database of lung nodules on {CT} scans},
	volume = {38},
	issn = {0094-2405},
	shorttitle = {The {Lung} {Image} {Database} {Consortium} ({LIDC}) and {Image} {Database} {Resource} {Initiative} ({IDRI})},
	doi = {10.1118/1.3528204},
	abstract = {PURPOSE: The development of computer-aided diagnostic (CAD) methods for lung nodule detection, classification, and quantitative assessment can be facilitated through a well-characterized repository of computed tomography (CT) scans. The Lung Image Database Consortium (LIDC) and Image Database Resource Initiative (IDRI) completed such a database, establishing a publicly available reference for the medical imaging research community. Initiated by the National Cancer Institute (NCI), further advanced by the Foundation for the National Institutes of Health (FNIH), and accompanied by the Food and Drug Administration (FDA) through active participation, this public-private partnership demonstrates the success of a consortium founded on a consensus-based process.
METHODS: Seven academic centers and eight medical imaging companies collaborated to identify, address, and resolve challenging organizational, technical, and clinical issues to provide a solid foundation for a robust database. The LIDC/IDRI Database contains 1018 cases, each of which includes images from a clinical thoracic CT scan and an associated XML file that records the results of a two-phase image annotation process performed by four experienced thoracic radiologists. In the initial blinded-read phase, each radiologist independently reviewed each CT scan and marked lesions belonging to one of three categories ("nodule {\textgreater} or =3 mm," "nodule {\textless}3 mm," and "non-nodule {\textgreater} or =3 mm"). In the subsequent unblinded-read phase, each radiologist independently reviewed their own marks along with the anonymized marks of the three other radiologists to render a final opinion. The goal of this process was to identify as completely as possible all lung nodules in each CT scan without requiring forced consensus.
RESULTS: The Database contains 7371 lesions marked "nodule" by at least one radiologist. 2669 of these lesions were marked "nodule {\textgreater} or =3 mm" by at least one radiologist, of which 928 (34.7\%) received such marks from all four radiologists. These 2669 lesions include nodule outlines and subjective nodule characteristic ratings.
CONCLUSIONS: The LIDC/IDRI Database is expected to provide an essential medical imaging research resource to spur CAD development, validation, and dissemination in clinical practice.},
	language = {eng},
	number = {2},
	journal = {Medical Physics},
	author = {Armato, Samuel G. and McLennan, Geoffrey and Bidaut, Luc and McNitt-Gray, Michael F. and Meyer, Charles R. and Reeves, Anthony P. and Zhao, Binsheng and Aberle, Denise R. and Henschke, Claudia I. and Hoffman, Eric A. and Kazerooni, Ella A. and MacMahon, Heber and Van Beeke, Edwin J. R. and Yankelevitz, David and Biancardi, Alberto M. and Bland, Peyton H. and Brown, Matthew S. and Engelmann, Roger M. and Laderach, Gary E. and Max, Daniel and Pais, Richard C. and Qing, David P. Y. and Roberts, Rachael Y. and Smith, Amanda R. and Starkey, Adam and Batrah, Poonam and Caligiuri, Philip and Farooqi, Ali and Gladish, Gregory W. and Jude, C. Matilda and Munden, Reginald F. and Petkovska, Iva and Quint, Leslie E. and Schwartz, Lawrence H. and Sundaram, Baskaran and Dodd, Lori E. and Fenimore, Charles and Gur, David and Petrick, Nicholas and Freymann, John and Kirby, Justin and Hughes, Brian and Casteele, Alessi Vande and Gupte, Sangeeta and Sallamm, Maha and Heath, Michael D. and Kuhn, Michael H. and Dharaiya, Ekta and Burns, Richard and Fryd, David S. and Salganicoff, Marcos and Anand, Vikram and Shreter, Uri and Vastagh, Stephen and Croft, Barbara Y.},
	month = feb,
	year = {2011},
	pmid = {21452728},
	pmcid = {PMC3041807},
	keywords = {Databases, Factual, Diagnosis, Computer-Assisted, Humans, Lung, Lung Neoplasms, Quality Control, Radiographic Image Interpretation, Computer-Assisted, Radiography, Thoracic, Reference Standards, Tomography, X-Ray Computed, Tumor Burden},
	pages = {915--931}
}

@inproceedings{sun_automatic_2017,
	title = {Automatic lung nodule graph cuts segmentation with deep learning false positive reduction},
	volume = {10134},
	url = {http://dx.doi.org/10.1117/12.2251302},
	doi = {10.1117/12.2251302},
	abstract = {To automatic detect lung nodules from CT images, we designed a two stage computer aided detection (CAD) system. The first stage is graph cuts segmentation to identify and segment the nodule candidates, and the second stage is convolutional neural network for false positive reduction. The dataset contains 595 CT cases randomly selected from Lung Image Database Consortium and Image Database Resource Initiative (LIDC/IDRI) and the 305 pulmonary nodules achieved diagnosis consensus by all four experienced radiologists were our detection targets. Consider each slice as an individual sample, 2844 nodules were included in our database. The graph cuts segmentation was conducted in a two-dimension manner, 2733 lung nodule ROIs are successfully identified and segmented. With a false positive reduction by a seven-layer convolutional neural network, 2535 nodules remain detected while the false positive dropped to 31.6\%. The average F-measure of segmented lung nodule tissue is 0.8501.},
	urldate = {2017-03-10},
	author = {Sun, Wenqing and Huang, Xia and Tseng, Tzu-Liang Bill and Qian, Wei},
	year = {2017},
	pages = {101343M--101343M--8},
	file = {Sun et al_2017_Automatic lung nodule graph cuts segmentation with deep learning false positive.pdf:C\:\\Users\\Benjamin Hillmann\\OneDrive\\Documents\\Zotfile\\Sun et al_2017_Automatic lung nodule graph cuts segmentation with deep learning false positive_2.pdf:application/pdf}
}

@misc{noauthor_united_nodate,
	title = {United {States} {Cancer} {Statistics}},
	url = {https://nccd.cdc.gov/uscs/toptencancers.aspx#text},
	urldate = {2017-04-17},
	file = {United States Cancer Statistics:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\S4ZWWDVG\\toptencancers.html:text/html}
}

@misc{noauthor_who_nodate,
	title = {{WHO} {\textbar} {Cancer}},
	url = {http://www.who.int/mediacentre/factsheets/fs297/en/},
	abstract = {Cancer is a generic term for a large group of diseases that can affect any part of the body.},
	urldate = {2017-04-17},
	journal = {WHO},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\S7SD78G7\\en.html:text/html}
}

@article{he_deep_2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2017-04-17},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	note = {arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\7SBCPK2E\\1512.html:text/html;He et al_2015_Deep Residual Learning for Image Recognition.pdf:C\:\\Users\\Benjamin Hillmann\\OneDrive\\Documents\\Zotfile\\He et al_2015_Deep Residual Learning for Image Recognition.pdf:application/pdf}
}

@inproceedings{yosinski_how_2014,
	title = {How transferable are features in deep neural networks?},
	url = {http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks},
	urldate = {2017-04-17},
	booktitle = {Advances in neural information processing systems},
	author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
	year = {2014},
	pages = {3320--3328},
	file = {Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\8F2GJ2K5\\Yosinski et al. - 2014 - How transferable are features in deep neural netwo.pdf:application/pdf}
}

@article{russakovsky_imagenet_2015,
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge}},
	volume = {115},
	doi = {10.1007/s11263-015-0816-y},
	abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5 years of the challenge, and propose future directions and improvements.},
	number = {3},
	journal = {International Journal of Computer Vision},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael S. and Berg, Alexander C. and Fei-Fei, Li},
	month = dec,
	year = {2015},
	keywords = {3d single object recognition, benchmark, cognitive neuroscience of visual object recognition, Computer science, Computer Vision, Data mining, data science, data set, mathematics},
	pages = {211--252}
}

@article{setio_validation_2016,
	title = {Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the {LUNA}16 challenge},
	shorttitle = {Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images},
	url = {http://arxiv.org/abs/1612.08012},
	abstract = {Automatic detection of pulmonary nodules in thoracic computed tomography (CT) scans has been an active area of research for the last two decades. However, there have only been few studies that provide a comparative performance evaluation of different systems on a common database. We have therefore set up the LUNA16 challenge, an objective evaluation framework for automatic nodule detection algorithms using the largest publicly available reference database of chest CT scans, the LIDC-IDRI data set. In LUNA16, participants develop their algorithm and upload their predictions on 888 CT scans in one of the two tracks: 1) the complete nodule detection track where a complete CAD system should be developed, or 2) the false positive reduction track where a provided set of nodule candidates should be classified. This paper describes the setup of LUNA16 and presents the results of the challenge so far. Moreover, the impact of combining individual systems on the detection performance was also investigated. It was observed that the leading solutions employed convolutional networks and used the provided set of nodule candidates. The combination of these solutions achieved an excellent sensitivity of over 95\% at fewer than 1.0 false positives per scan. This highlights the potential of combining algorithms to improve the detection performance. Our observer study with four expert readers has shown that the best system detects nodules that were missed by expert readers who originally annotated the LIDC-IDRI data. We released this set of additional nodules for further development of CAD systems.},
	urldate = {2017-04-18},
	journal = {arXiv:1612.08012 [cs]},
	author = {Setio, Arnaud Arindra Adiyoso and Traverso, Alberto and de Bel, Thomas and Berens, Moira S. N. and Bogaard, Cas van den and Cerello, Piergiorgio and Chen, Hao and Dou, Qi and Fantacci, Maria Evelina and Geurts, Bram and van der Gugten, Robbert and Heng, Pheng Ann and Jansen, Bart and de Kaste, Michael M. J. and Kotov, Valentin and Lin, Jack Yu-Hung and Manders, Jeroen T. M. C. and Sónora-Mengana, Alexander and García-Naranjo, Juan Carlos and Prokop, Mathias and Saletta, Marco and Schaefer-Prokop, Cornelia M. and Scholten, Ernst T. and Scholten, Luuk and Snoeren, Miranda M. and Torres, Ernesto Lopez and Vandemeulebroucke, Jef and Walasek, Nicole and Zuidhof, Guido C. A. and van Ginneken, Bram and Jacobs, Colin},
	month = dec,
	year = {2016},
	note = {arXiv: 1612.08012},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\7PTE6E7Q\\1612.html:text/html;Setio et al_2016_Validation, comparison, and combination of algorithms for automatic detection.pdf:C\:\\Users\\Benjamin Hillmann\\OneDrive\\Documents\\Zotfile\\Setio et al_2016_Validation, comparison, and combination of algorithms for automatic detection.pdf:application/pdf}
}

@misc{vansteenkiste_predicting_nodate,
	title = {Predicting lung cancer},
	url = {https://EliasVansteenkiste.github.io/machine%20learning/lung-cancer-pred/},
	abstract = {Description of our solution for Kaggle's third Data Science Bowl.},
	urldate = {2017-04-18},
	journal = {Keep Your Learning Rate High},
	author = {Vansteenkiste, Elias},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\P6MKN26Z\\lung-cancer-pred.html:text/html}
}

@misc{noauthor_hounsfield_2017,
	title = {Hounsfield scale},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Hounsfield_scale&oldid=768281205},
	abstract = {The Hounsfield scale /ˈhaʊnzˌfiːld/ or CT numbers, named after Sir Godfrey Newbold Hounsfield, is a quantitative scale for describing radiodensity.},
	language = {en},
	urldate = {2017-04-18},
	journal = {Wikipedia},
	month = mar,
	year = {2017},
	note = {Page Version ID: 768281205},
	file = {Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\A2BH65Q3\\index.html:text/html}
}

@misc{noauthor_data_nodate,
	title = {Data {Science} {Bowl} 2017 {\textbar} {Kaggle}},
	url = {https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial},
	urldate = {2017-04-18},
	file = {Data Science Bowl 2017 | Kaggle:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\4KSDHC5D\\full-preprocessing-tutorial.html:text/html}
}

@article{erhan_visualizing_2009,
	title = {Visualizing higher-layer features of a deep network},
	volume = {1341},
	url = {https://www.researchgate.net/profile/Aaron_Courville/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network/links/53ff82b00cf24c81027da530.pdf},
	urldate = {2017-04-18},
	journal = {University of Montreal},
	author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	year = {2009},
	pages = {3},
	file = {Erhan+2009+Visualizing+higher+layer+features+of+a+deep+network.pdf:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\NTEGC2GP\\Erhan+2009+Visualizing+higher+layer+features+of+a+deep+network.pdf:application/pdf}
}

@article{friedman_greedy_2000,
	title = {Greedy {Function} {Approximation}: {A} {Gradient} {Boosting} {Machine}},
	volume = {29},
	shorttitle = {Greedy {Function} {Approximation}},
	abstract = {Function approximation is viewed from the perspective of numerical optimization in  function space, rather than parameter space. A connection is made between stagewise additive  expansions and steepest\{\vphantom{\}}descent minimization. A general gradient\{\vphantom{\}}descent {\textbackslash}boosting"  paradigm is developed for additive expansions based on any tting criterion. Specic algorithms  are presented for least\{\vphantom{\}}squares, least\{\vphantom{\}}absolute\{\vphantom{\}}deviation, and Huber\{\vphantom{\}}M loss functions  for regression, and multi\{\vphantom{\}}class logistic likelihood for classication. Special enhancements  are derived for the particular case where the individual additive components are regression  trees, and tools for interpreting such {\textbackslash}TreeBoost" models are presented. Gradient  boosting of regression trees produces competitive, highly robust, interpretable procedures  for both regression and classication, especially appropriate for mining less than clean data.  Connections between this approach and the boosting methods of Freund and Shapire 1996,  and Frie...},
	journal = {Annals of Statistics},
	author = {Friedman, Jerome H.},
	year = {2000},
	pages = {1189--1232},
	file = {Citeseer - Snapshot:C\:\\Users\\Benjamin Hillmann\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\67lkoljj.default\\zotero\\storage\\KFZHBKP9\\summary.html:text/html;Friedman_2000_Greedy Function Approximation.pdf:C\:\\Users\\Benjamin Hillmann\\OneDrive\\Documents\\Zotfile\\Friedman_2000_Greedy Function Approximation.pdf:application/pdf}
}